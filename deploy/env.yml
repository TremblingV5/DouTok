version: "3"

volumes:
    redis_vol:
    mysql_vol:
    zoo_vol:
    kafka_vol:
    hb_vol:
    hadoop_namenode:
    hadoop_datanode:
    hadoop_historyserver:
    hbase_data:
    hbase_zookeeper_data:
    prometheus_data:

networks:
    total:
        driver: bridge

services:
    redis:
        image: redis:latest
        command: redis-server /etc/redis/redis.conf
        networks:
            - total
        volumes:
            - redis_vol:/data
            - ./redis.conf:/etc/redis/redis.conf
        ports:
            - "6379:6379"
        restart: always

    mysql:
        image: mysql:8.0
        env_file:
            - ./.env
        networks:
            - total
        volumes:
            - mysql_vol:/var/lib/mysql:rw
            - ./my.cnf:/etc/mysql/my.cnf
        ports:
            - "3307:3307"
        restart: always

    # zookeeper:
    #     image: wurstmeister/zookeeper:3.4.6
    #     networks:
    #         - total
    #     volumes:
    #         - zoo_vol:/opt/zookeeper-3.4.6/data
    #     container_name: zookeeper
    #     ports:
    #         - "2180:2181"
    #         - "2182:2182"
    #     restart: always

    kafka:
        image: wurstmeister/kafka
        container_name: kafka
        networks:
            - total
        depends_on:
            - hbase
        ports:
            - "9092:9092"
        volumes:
            - kafka_vol:/kafka
        environment:
            - KAFKA_LISTENERS=PLAINTEXT://kafka:9092
            - KAFKA_ADVERTISED_NAME=kafka
            - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.3.165:9092
            - KAFKA_ZOOKEEPER_CONNECT=hbase:2181
            - KAFKA_HEAP_OPTS=-Xmx512M -Xms16M
        restart: always

    kafka-manager:
        image: sheepkiller/kafka-manager
        networks:
            - total
        ports:
            - "9099:9000"
        environment:
            - ZK_HOSTS=hbase:2181
        depends_on:
            - hbase
            - kafka
        restart: always

    mongo:
        image: mongo:6.0.3
        networks:
            - total
        ports:
            - "27017:27017"
        environment:
            - MONGO_INITDB_ROOT_USERNAME=root
            - MONGO_INITDB_ROOT_PASSWORD=root
        restart: always

    hbase:
        # image: harisekhon/hbase:2.1
        build: ./hbase
        container_name: hbase
        hostname: master
        networks:
            - total
        ports:
            - "16000:16000"
            - "16010:16010"
            - "16020:16020"
            - "16030:16030"
            - "16201:16201"
            - "9090:9090"
            - "9095:9095"
            - "2181:2181"
        volumes:
            # - hb_vol:/hbase-data
            - ./hbase-data:/hbase-data
            # - ./hbase-conf:/hbase-2.1.3/conf
            # - ./hbase-conf:/hbase/conf
            - ./hbase-zoo-data:/zookeeper-data
        environment:
            - HBASE_CONF_hbase_cluster_distributed=false
        restart: always

    etcd:
        image: quay.io/coreos/etcd
        container_name: etcd
        networks:
            - total
        command: etcd -name etcd -advertise-client-urls http://0.0.0.0:2379 -listen-client-urls http://0.0.0.0:2379 -listen-peer-urls http://0.0.0.0:2380
        ports:
            - "2379:2379"
            - "2380:2380"
        restart: always

    es:
        image: elasticsearch:7.13.1
        container_name: es
        networks:
            - total
        environment:
            - TZ=Asia/Shanghai
            - discovery.type=single-node
            - ES_JAVA_OPTS=-Xms512m -Xmx512m
            - http.port=9200
        privileged: true
        ports:
            - "9200:9200"
        restart: always

    otel-collector:
        image: otel/opentelemetry-collector-contrib-dev:latest
        command: [ "--config=/etc/otel-collector-config.yml", "${OTELCOL_ARGS}" ]
        volumes:
            - ./otel-collector-config.yml:/etc/otel-collector-config.yml
        ports:
            - "1888:1888"   # pprof extension
            - "8888:8888"   # Prometheus metrics exposed by the collector
            - "8889:8889"   # Prometheus exporter metrics
            - "13133:13133" # health_check extension
            - "4317:4317"   # OTLP gRPC receiver
            - "55670:55679" # zpages extension
        depends_on:
            - jaeger-all-in-one

    jaeger-all-in-one:
        platform: linux/x86_64
        image: rancher/jaegertracing-all-in-one:1.20.0
        container_name: jaeger
        networks:
            - total
        environment:
            - TZ=Asia/Shanghai
            - SPAN_STORAGE_TYPE=elasticsearch
            - ES_SERVER_URLS=http://es:9200
            - LOG_LEVEL=debug
            # - JAEGER_SAMPLER_MANAGER_HOST_PORT:jaeger:5778
        depends_on:
            - es
        privileged: true
        ports:
            - "6831:6831/udp"
            - "6832:6832/udp"
            - "5778:5778"
            - "16686:16686"
            - "4318:4318"
            - "14250:14250"
            - "14268:14268"
            - "14269:14269"
            - "9411:9411"
        restart: always

    victoriametrics:
        container_name: victoriametrics
        image: victoriametrics/victoria-metrics
        ports:
            - "8428:8428"
            - "8089:8089"
            - "8089:8089/udp"
            - "2003:2003"
            - "2003:2003/udp"
            - "4242:4242"
        command:
            - '--storageDataPath=/storage'
            - '--graphiteListenAddr=:2003'
            - '--opentsdbListenAddr=:4242'
            - '--httpListenAddr=:8428'
            - '--influxListenAddr=:8089'
        restart: always

    grafana:
        image: grafana/grafana:latest
        environment:
            - GF_AUTH_ANONYMOUS_ENABLED=true
            - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
            - GF_AUTH_DISABLE_LOGIN_FORM=true
        ports:
            - "3000:3000"